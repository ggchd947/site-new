+++
title = 'AI Doomerism'
date = 2024-05-02T17:50:29-07:00
+++

### Some Key Definitions
- **EA:** Effective Altruism.
- **OPP:** **OP**en**P**hil or Open Philanthropy, an organization that provides grants based on the doctrine of Effective Altruism.
- **x-risk:** existential risk.
- **Peter Singer Theory:** We should help people as long as we do not sacrifice anything "morally significant".
- **Longtermism:** Refers to a set of ethical views concerned with protecting and improving the long-run future.

### Effective Altruism's Bait-and-Switch: From Global Poverty to AI Doomerism
The Effective Altruism founders planned - from day one - to mislead donors and new members in order to build the movement's brand and community:
![mislead donors](/img/ai-doomerism/mislead-donors.jpg)

The public-facing discourse of "giving to the poor" was a mirage designed to get people into the Effective Altruism (EA) movement and then lead them to the "core EA", x-risk, which is discussed in inward-facing spaces:
![giving to the poor](/img/ai-doomerism/giving-to-the-poor.jpeg)
> Effective Altruism founder, Will MacAskill - June 2012

![x-risk](/img/ai-doomerism/x-risk.jpg)
> Effective Altruism founder, Will MacAskill - November 2012

The guidance was to promote the publicly-facing cause (global poverty) and keep quiet about the core cause (AI x-risk):
![global poverty](/img/ai-doomerism/global-poverty.jpg)

In 2014 -- Peter Wildeford published a conversation about "EA Marketing" with EA communications specialist Michael Bitton.

Wildeford is the co-founder and co-CEO of Rethink Priorities and Chief Advisory Executive at IAPS (Institute for AI Policy and Strategy):
![peter wildeford](/img/ai-doomerism/iaps.png)

Jan Kulveit, who leads the European Summer Program on Rationality (ESPR), shared this on Facebook in 2018:
![Jan Kulveit](/img/ai-doomerism/espr.png)

As Effective Altruists engaged more deeply with the movement, they were encouraged to shift to AI x-risk:
![shift to ai](/img/ai-doomerism/shift-to-ai.png)

In 2019 -- EA Hub published a guide: "Tips to help your conversation go well."
Among the tips like "Use the person's interest", there was "Preventing 'Bait and Switch'":
![bait and switch](/img/ai-doomerism/bait-and-switch.png)

### Key Takeways
In the Public-facing/grassroots EAs (audience, followers, participants):
1. The main focus is effective giving via Peter Singer Theory
2. The main cause area is global health, targeting the 'distant poor' in developing countries.
3. The donors support organizations doing direct anti-poverty work.

In the Core/highly engaged EAs (contributors, core, leadership):
1. The main focus is x-risk/longtermism (Nick Bostrom & Eliezer Yudkowsky).
2. The main cause areas are x-risk, AI-safety, 'global priorities research,' and EA movement-building.
3. The donors support highly-engaged EAs to build career capital, boost their productivity, and/or start new EA organizations; research; policy-making/agenda setting.

---

